{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Rotation Forest Implementation\n",
    "# Based on the paper \"Rotation Forest: A New Classifier Ensemble Method\"\n",
    "#\n",
    "# Dataset: Breast Cancer Wisconsin (Diagnostic) Dataset\n",
    "# URL: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)\n",
    "# - 569 samples (357 benign, 212 malignant)\n",
    "# - 30 numeric features (mean, SE, and \"worst\" values for 10 measurements)\n",
    "# - Binary classification task"
   ],
   "id": "68ff8b4be101bc3f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T20:11:28.790261Z",
     "start_time": "2026-01-17T20:11:28.174951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from decision_tree import *\n",
    "from classification_metrics import *"
   ],
   "id": "b7725642c8b4b859",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load and prepare Breast Cancer Wisconsin dataset",
   "id": "58ec8159b0df29d0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T20:11:29.421470Z",
     "start_time": "2026-01-17T20:11:29.380519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load data - first column is ID (skip), second is diagnosis (M=malignant, B=benign)\n",
    "df = pd.read_csv(\"data/wdbc.data\", sep=\",\", header=None)\n",
    "\n",
    "# Create feature names based on UCI repository documentation\n",
    "feature_names = [\n",
    "    \"radius_mean\", \"texture_mean\", \"perimeter_mean\", \"area_mean\", \"smoothness_mean\",\n",
    "    \"compactness_mean\", \"concavity_mean\", \"concave_points_mean\", \"symmetry_mean\", \"fractal_dimension_mean\",\n",
    "    \"radius_se\", \"texture_se\", \"perimeter_se\", \"area_se\", \"smoothness_se\",\n",
    "    \"compactness_se\", \"concavity_se\", \"concave_points_se\", \"symmetry_se\", \"fractal_dimension_se\",\n",
    "    \"radius_worst\", \"texture_worst\", \"perimeter_worst\", \"area_worst\", \"smoothness_worst\",\n",
    "    \"compactness_worst\", \"concavity_worst\", \"concave_points_worst\", \"symmetry_worst\", \"fractal_dimension_worst\"\n",
    "]\n",
    "\n",
    "header = [\"ID\", \"Diagnosis\"] + feature_names\n",
    "df.columns = header\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(df['Diagnosis'].value_counts())\n",
    "df.head()"
   ],
   "id": "4cd5857239202600",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (569, 32)\n",
      "\n",
      "Class distribution:\n",
      "Diagnosis\n",
      "B    357\n",
      "M    212\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "         ID Diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave_points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave_points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.4601                  0.11890  \n",
       "1          0.2750                  0.08902  \n",
       "2          0.3613                  0.08758  \n",
       "3          0.6638                  0.17300  \n",
       "4          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave_points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave_points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T20:11:40.970936Z",
     "start_time": "2026-01-17T20:11:40.962912Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare features and labels\n",
    "X = df.iloc[:,2:]  # Skip ID and Diagnosis columns\n",
    "y_raw = df.iloc[:,1]  # Diagnosis column\n",
    "\n",
    "# Convert M/B to 1/0\n",
    "y = (y_raw == 'M').astype(int)  # M (malignant) = 1, B (benign) = 0\n",
    "\n",
    "print(\"feature_names:\", list(X.columns))\n",
    "print(\"target_names: ['Benign (0)', 'Malignant (1)']\")\n",
    "\n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n",
    "print(f\"\\nX.shape: {X.shape}\")\n",
    "print(f\"y.shape: {y.shape}\")\n",
    "print(f\"Class 0 (Benign): {np.sum(y == 0)} samples\")\n",
    "print(f\"Class 1 (Malignant): {np.sum(y == 1)} samples\")"
   ],
   "id": "b7e17dd4aa3dcd20",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_names: ['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave_points_mean', 'symmetry_mean', 'fractal_dimension_mean', 'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se', 'compactness_se', 'concavity_se', 'concave_points_se', 'symmetry_se', 'fractal_dimension_se', 'radius_worst', 'texture_worst', 'perimeter_worst', 'area_worst', 'smoothness_worst', 'compactness_worst', 'concavity_worst', 'concave_points_worst', 'symmetry_worst', 'fractal_dimension_worst']\n",
      "target_names: ['Benign (0)', 'Malignant (1)']\n",
      "\n",
      "X.shape: (569, 30)\n",
      "y.shape: (569,)\n",
      "Class 0 (Benign): 357 samples\n",
      "Class 1 (Malignant): 212 samples\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Train-test split: 80% train, 20% test\n",
    "np.random.seed(777)\n",
    "ind_train = np.random.choice(X.shape[0], size=int(X.shape[0] * 0.8), replace=False)\n",
    "bool_ind_train = np.isin(range(X.shape[0]), ind_train)\n",
    "X_train = X[bool_ind_train,]\n",
    "y_train = y[bool_ind_train]\n",
    "X_test = X[~bool_ind_train,]\n",
    "y_test = y[~bool_ind_train]\n",
    "print(\"X_train.shape:\", X_train.shape)\n",
    "print(\"y_train.shape:\", y_train.shape)\n",
    "print(\"X_test.shape:\", X_test.shape)\n",
    "print(\"y_test.shape:\", y_test.shape)"
   ],
   "id": "9fc0da8f8f137b95"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Helper functions for PCA (from PCA notebook)",
   "id": "a3d1b092de4816d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_mean_std(X):\n",
    "    return np.mean(X, axis=0), np.std(X, axis=0)\n",
    "\n",
    "def normalization(X, means=None, sds=None):\n",
    "    X = X.copy()  # don't modify original data\n",
    "    for j in range(X.shape[1]):\n",
    "        if means is not None:\n",
    "            X[:,j] = (X[:,j] - means[j])\n",
    "        if sds is not None:\n",
    "            X[:,j] = X[:,j] / sds[j]\n",
    "    return X\n",
    "\n",
    "def get_principal_components(covariance_matrix):\n",
    "    eigen_values, eigen_vectors = np.linalg.eig(covariance_matrix)\n",
    "\n",
    "    # Sort by eigenvalues in descending order\n",
    "    order = np.argsort(eigen_values)[::-1]\n",
    "    eigen_values = eigen_values[order]\n",
    "    eigen_vectors = eigen_vectors[:,order]\n",
    "\n",
    "    return eigen_values, eigen_vectors"
   ],
   "id": "e11f48d4f8495d37"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Majority voting function (from Random Forest notebook)",
   "id": "bdfe0ec7f82fa14c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def majority_voting(yHats):\n",
    "    \"\"\"Aggregate predictions from multiple trees using majority voting\"\"\"\n",
    "    yHat = []\n",
    "    for i in range(yHats.shape[1]):\n",
    "        vals, counts = np.unique(yHats[:,i], return_counts=True)\n",
    "        index = np.argmax(counts)\n",
    "        yHat.append(int(vals[index]))\n",
    "    return yHat"
   ],
   "id": "43949eb63771b6a2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Rotation Forest specific functions",
   "id": "9ea7d4304e2fc8c7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def create_feature_subsets(n_features, M=3):\n",
    "    \"\"\"\n",
    "    Create disjoint feature subsets with fixed size M.\n",
    "    If n_features is not divisible by M, the remainder subset is filled with random features.\n",
    "\n",
    "    Parameters:\n",
    "    - n_features: total number of features\n",
    "    - M: fixed subset size (default: 3)\n",
    "\n",
    "    Returns:\n",
    "    - List of feature index arrays (disjoint subsets)\n",
    "    \"\"\"\n",
    "    K = int(np.ceil(n_features / M))  # number of subsets\n",
    "    feature_indices = np.random.permutation(n_features)  # shuffle features\n",
    "\n",
    "    subsets = []\n",
    "    for k in range(K):\n",
    "        start_idx = k * M\n",
    "        end_idx = min(start_idx + M, n_features)\n",
    "        subset = feature_indices[start_idx:end_idx].tolist()\n",
    "\n",
    "        # If this is the last subset and it has fewer than M features, fill with random features\n",
    "        if len(subset) < M and k == K - 1:\n",
    "            available_features = feature_indices[:start_idx].tolist()  # features already used\n",
    "            needed = M - len(subset)\n",
    "            random_fill = np.random.choice(available_features, size=needed, replace=False)\n",
    "            subset.extend(random_fill)\n",
    "\n",
    "        subsets.append(np.array(subset))\n",
    "\n",
    "    return subsets\n",
    "\n",
    "def compute_pca_rotation_for_subset(X_bootstrap, feature_subset):\n",
    "    \"\"\"\n",
    "    Compute PCA rotation matrix for a feature subset.\n",
    "\n",
    "    Parameters:\n",
    "    - X_bootstrap: bootstrapped training data\n",
    "    - feature_subset: indices of features in this subset\n",
    "\n",
    "    Returns:\n",
    "    - eigen_vectors: PCA rotation matrix (all components kept)\n",
    "    - means: mean values for mean-centering\n",
    "    \"\"\"\n",
    "    # Extract features for this subset\n",
    "    X_subset = X_bootstrap[:, feature_subset]\n",
    "\n",
    "    # Compute mean and mean-center the data (standard PCA preprocessing)\n",
    "    means, _ = get_mean_std(X_subset)\n",
    "    X_centered = normalization(X_subset, means=means, sds=None)\n",
    "\n",
    "    # Compute covariance matrix and PCA\n",
    "    covariance_matrix = np.cov(X_centered.T)\n",
    "    eigen_values, eigen_vectors = get_principal_components(covariance_matrix)\n",
    "\n",
    "    # Keep all components as per paper specification\n",
    "    return eigen_vectors, means\n",
    "\n",
    "def rotation_forest(X, y, L=10, M=3, max_depth=15, bootstrap_pca_fraction=0.75):\n",
    "    \"\"\"\n",
    "    Train Rotation Forest ensemble.\n",
    "\n",
    "    Parameters:\n",
    "    - X: training features\n",
    "    - y: training labels\n",
    "    - L: number of trees (default: 10)\n",
    "    - M: subset size (default: 3)\n",
    "    - max_depth: maximum tree depth (default: 15)\n",
    "    - bootstrap_pca_fraction: fraction of data for PCA bootstrap (default: 0.75)\n",
    "\n",
    "    Returns:\n",
    "    - List of dictionaries containing tree, rotation_info for each classifier\n",
    "    \"\"\"\n",
    "    n_samples, n_features = X.shape\n",
    "    n_classes = len(set(y))\n",
    "    ensemble = []\n",
    "\n",
    "    for l in range(L):\n",
    "        # Step 1: Bootstrap sample for tree training (100% with replacement)\n",
    "        tree_indices = np.random.choice(n_samples, size=n_samples, replace=True)\n",
    "        X_tree = X[tree_indices]\n",
    "        y_tree = y[tree_indices]\n",
    "\n",
    "        # Step 2: Create disjoint feature subsets\n",
    "        feature_subsets = create_feature_subsets(n_features, M=M)\n",
    "\n",
    "        # Step 3: Bootstrap sample for PCA (75% without replacement)\n",
    "        pca_sample_size = int(n_samples * bootstrap_pca_fraction)\n",
    "        pca_indices = np.random.choice(n_samples, size=pca_sample_size, replace=False)\n",
    "        X_pca_bootstrap = X[pca_indices]\n",
    "\n",
    "        # Step 4: Apply PCA to each feature subset\n",
    "        rotation_matrices = []\n",
    "        subset_means = []\n",
    "\n",
    "        for subset in feature_subsets:\n",
    "            eigen_vectors, means = compute_pca_rotation_for_subset(X_pca_bootstrap, subset)\n",
    "            rotation_matrices.append(eigen_vectors)\n",
    "            subset_means.append(means)\n",
    "\n",
    "        # Step 5: Transform training data using rotation\n",
    "        X_tree_rotated = apply_rotation_transform(X_tree, feature_subsets, rotation_matrices, subset_means)\n",
    "\n",
    "        # Step 6: Build decision tree on rotated features\n",
    "        tree = build_tree(X_tree_rotated, y_tree, n_classes, max_depth=max_depth, max_features=None)\n",
    "\n",
    "        # Store tree with rotation information\n",
    "        ensemble.append({\n",
    "            'tree': tree,\n",
    "            'feature_subsets': feature_subsets,\n",
    "            'rotation_matrices': rotation_matrices,\n",
    "            'subset_means': subset_means\n",
    "        })\n",
    "\n",
    "    return ensemble\n",
    "\n",
    "def apply_rotation_transform(X, feature_subsets, rotation_matrices, subset_means):\n",
    "    \"\"\"\n",
    "    Apply rotation transformation to data using stored PCA rotations.\n",
    "\n",
    "    Parameters:\n",
    "    - X: data to transform\n",
    "    - feature_subsets: list of feature indices for each subset\n",
    "    - rotation_matrices: list of PCA rotation matrices\n",
    "    - subset_means: list of mean vectors for each subset\n",
    "\n",
    "    Returns:\n",
    "    - X_rotated: transformed data\n",
    "    \"\"\"\n",
    "    n_samples = X.shape[0]\n",
    "    rotated_features = []\n",
    "\n",
    "    # Apply rotation to each feature subset\n",
    "    for subset, rotation_matrix, means in zip(feature_subsets, rotation_matrices, subset_means):\n",
    "        # Extract subset features\n",
    "        X_subset = X[:, subset]\n",
    "\n",
    "        # Mean-center using stored means\n",
    "        X_centered = normalization(X_subset, means=means, sds=None)\n",
    "\n",
    "        # Apply PCA rotation (project onto principal components)\n",
    "        X_subset_rotated = np.dot(X_centered, rotation_matrix)\n",
    "\n",
    "        rotated_features.append(X_subset_rotated)\n",
    "\n",
    "    # Concatenate all rotated subsets to form full feature space\n",
    "    X_rotated = np.concatenate(rotated_features, axis=1)\n",
    "\n",
    "    return X_rotated\n",
    "\n",
    "def rotation_forest_predict(ensemble, X):\n",
    "    \"\"\"\n",
    "    Make predictions using Rotation Forest ensemble.\n",
    "\n",
    "    Parameters:\n",
    "    - ensemble: list of trained trees with rotation info\n",
    "    - X: test data\n",
    "\n",
    "    Returns:\n",
    "    - predictions: ensemble predictions using majority voting\n",
    "    \"\"\"\n",
    "    L = len(ensemble)\n",
    "    yHats = np.zeros((L, X.shape[0]))\n",
    "\n",
    "    for l in range(L):\n",
    "        # Apply rotation transformation\n",
    "        X_rotated = apply_rotation_transform(\n",
    "            X,\n",
    "            ensemble[l]['feature_subsets'],\n",
    "            ensemble[l]['rotation_matrices'],\n",
    "            ensemble[l]['subset_means']\n",
    "        )\n",
    "\n",
    "        # Get predictions from tree\n",
    "        yHats[l,] = predict(ensemble[l]['tree'], X_rotated)\n",
    "\n",
    "    # Aggregate predictions using majority voting\n",
    "    return majority_voting(yHats)"
   ],
   "id": "44a4c8791d729693"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train Rotation Forest",
   "id": "b222104981378f89"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"Training Rotation Forest ensemble...\")\n",
    "np.random.seed(777)\n",
    "rotation_forest_ensemble = rotation_forest(X_train, y_train, L=10, M=3, max_depth=15)\n",
    "print(f\"Trained Rotation Forest with {len(rotation_forest_ensemble)} trees\")"
   ],
   "id": "5ae4c1e80932e2ee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluate Rotation Forest",
   "id": "da9e34b36f76cdf3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "yHat_rotation = rotation_forest_predict(rotation_forest_ensemble, X_test)\n",
    "_, confusion_mat_rotation = confusion_matrix(y_test, yHat_rotation)\n",
    "accuracy_rotation = accuracy(confusion_mat_rotation)\n",
    "print(\"Rotation Forest accuracy on test data:\", accuracy_rotation)\n",
    "print(\"Confusion matrix:\\n\", confusion_mat_rotation)"
   ],
   "id": "8f9051d89f5cf752"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train baseline Random Forest for comparison",
   "id": "769919ab7985fc79"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def random_forest(X, y, K, max_depth=100):\n",
    "    \"\"\"Standard Random Forest implementation (baseline)\"\"\"\n",
    "    decision_trees = []\n",
    "    for k in range(K):\n",
    "        ind = np.random.choice(X.shape[0], size=X.shape[0], replace=True)\n",
    "        X_sample = X[ind,]\n",
    "        y_sample = y[ind]\n",
    "        decision_trees.append(build_tree(X_sample, y_sample, len(set(y_sample)), max_features=\"sqrt\", max_depth=max_depth))\n",
    "    return decision_trees\n",
    "\n",
    "def random_forest_predict(decision_trees, X):\n",
    "    \"\"\"Standard Random Forest prediction\"\"\"\n",
    "    K = len(decision_trees)\n",
    "    yHats = np.zeros((K, X.shape[0]))\n",
    "    for k in range(K):\n",
    "        yHats[k,] = predict(decision_trees[k], X)\n",
    "    return majority_voting(yHats)"
   ],
   "id": "6d30d36a104eaacb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"Training Random Forest baseline...\")\n",
    "np.random.seed(777)\n",
    "random_forest_ensemble = random_forest(X_train, y_train, K=10, max_depth=15)\n",
    "print(f\"Trained Random Forest with {len(random_forest_ensemble)} trees\")"
   ],
   "id": "d5573a3b90adfa04"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluate Random Forest baseline",
   "id": "3dd3b906d7c397fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "yHat_rf = random_forest_predict(random_forest_ensemble, X_test)\n",
    "_, confusion_mat_rf = confusion_matrix(y_test, yHat_rf)\n",
    "accuracy_rf = accuracy(confusion_mat_rf)\n",
    "print(\"Random Forest accuracy on test data:\", accuracy_rf)\n",
    "print(\"Confusion matrix:\\n\", confusion_mat_rf)"
   ],
   "id": "bb5dbcd48108407e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Comparison: Rotation Forest vs Random Forest",
   "id": "15c654ae8a38be03"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"PERFORMANCE COMPARISON\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Rotation Forest accuracy: {accuracy_rotation:.4f}\")\n",
    "print(f\"Random Forest accuracy:   {accuracy_rf:.4f}\")\n",
    "print(f\"Improvement:              {(accuracy_rotation - accuracy_rf):.4f}\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\nRotation Forest applies PCA-based feature rotation to each tree,\")\n",
    "print(\"which increases diversity among trees and improves ensemble performance.\")"
   ],
   "id": "79eb7d85dc874118"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluate individual tree accuracies",
   "id": "9be0a1ffe7ddab90"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_individual_tree_accuracies_rotation(ensemble, X_test, y_test):\n",
    "    \"\"\"Get accuracy of each individual tree in Rotation Forest\"\"\"\n",
    "    accuracies = []\n",
    "    for classifier in ensemble:\n",
    "        X_rotated = apply_rotation_transform(\n",
    "            X_test,\n",
    "            classifier['feature_subsets'],\n",
    "            classifier['rotation_matrices'],\n",
    "            classifier['subset_means']\n",
    "        )\n",
    "        yHat = predict(classifier['tree'], X_rotated)\n",
    "        _, confusion_mat = confusion_matrix(y_test, yHat)\n",
    "        accuracies.append(accuracy(confusion_mat))\n",
    "    return accuracies\n",
    "\n",
    "def get_individual_tree_accuracies_rf(trees, X_test, y_test):\n",
    "    \"\"\"Get accuracy of each individual tree in Random Forest\"\"\"\n",
    "    accuracies = []\n",
    "    for tree in trees:\n",
    "        yHat = predict(tree, X_test)\n",
    "        _, confusion_mat = confusion_matrix(y_test, yHat)\n",
    "        accuracies.append(accuracy(confusion_mat))\n",
    "    return accuracies"
   ],
   "id": "837ab1aec5ef9627"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "acc_rotation_individual = get_individual_tree_accuracies_rotation(rotation_forest_ensemble, X_test, y_test)\n",
    "acc_rf_individual = get_individual_tree_accuracies_rf(random_forest_ensemble, X_test, y_test)\n",
    "\n",
    "print(\"Rotation Forest - Individual tree accuracies:\")\n",
    "print(f\"  Mean: {np.mean(acc_rotation_individual):.4f}\")\n",
    "print(f\"  Std:  {np.std(acc_rotation_individual):.4f}\")\n",
    "print(f\"  Min:  {np.min(acc_rotation_individual):.4f}\")\n",
    "print(f\"  Max:  {np.max(acc_rotation_individual):.4f}\")\n",
    "\n",
    "print(\"\\nRandom Forest - Individual tree accuracies:\")\n",
    "print(f\"  Mean: {np.mean(acc_rf_individual):.4f}\")\n",
    "print(f\"  Std:  {np.std(acc_rf_individual):.4f}\")\n",
    "print(f\"  Min:  {np.min(acc_rf_individual):.4f}\")\n",
    "print(f\"  Max:  {np.max(acc_rf_individual):.4f}\")\n",
    "\n",
    "print(\"\\nEnsemble accuracies:\")\n",
    "print(f\"  Rotation Forest: {accuracy_rotation:.4f}\")\n",
    "print(f\"  Random Forest:   {accuracy_rf:.4f}\")"
   ],
   "id": "b13d6b5723aeba61"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Visualization: Individual vs Ensemble Performance",
   "id": "73656136d5a8b4a1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot individual tree accuracies\n",
    "ax1.plot(range(1, 11), acc_rotation_individual, 'o-', label='Rotation Forest', color='blue', linewidth=2)\n",
    "ax1.plot(range(1, 11), acc_rf_individual, 's-', label='Random Forest', color='green', linewidth=2)\n",
    "ax1.axhline(y=accuracy_rotation, color='blue', linestyle='--', label='RotForest Ensemble', alpha=0.7)\n",
    "ax1.axhline(y=accuracy_rf, color='green', linestyle='--', label='RandForest Ensemble', alpha=0.7)\n",
    "ax1.set_xlabel('Tree Index')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_title('Individual Tree Accuracies')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot comparison bar chart\n",
    "methods = ['Rotation Forest', 'Random Forest']\n",
    "accuracies = [accuracy_rotation, accuracy_rf]\n",
    "colors = ['blue', 'green']\n",
    "ax2.bar(methods, accuracies, color=colors, alpha=0.7)\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title('Ensemble Performance Comparison')\n",
    "ax2.set_ylim([0.85, 1.0])\n",
    "for i, v in enumerate(accuracies):\n",
    "    ax2.text(i, v + 0.005, f'{v:.4f}', ha='center', fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "efdbabdde18d6e0f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Hyperparameter Tuning\n",
    "# Testing different values of L (number of trees) and max_depth"
   ],
   "id": "ea6899e1f48d4d6c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create validation split: 60% train, 20% validation, 20% test\n",
    "np.random.seed(777)\n",
    "n_total = X_train.shape[0]\n",
    "n_val = int(n_total * 0.25)  # 20% of original data = 25% of training data\n",
    "\n",
    "ind_val = np.random.choice(n_total, size=n_val, replace=False)\n",
    "bool_ind_val = np.isin(range(n_total), ind_val)\n",
    "\n",
    "X_train_tuning = X_train[~bool_ind_val]\n",
    "y_train_tuning = y_train[~bool_ind_val]\n",
    "X_val = X_train[bool_ind_val]\n",
    "y_val = y_train[bool_ind_val]\n",
    "\n",
    "print(\"Tuning set sizes:\")\n",
    "print(f\"  X_train_tuning: {X_train_tuning.shape}\")\n",
    "print(f\"  X_val: {X_val.shape}\")\n",
    "print(f\"  X_test: {X_test.shape}\")"
   ],
   "id": "4e1dc0994a41095a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Hyperparameter grid search\n",
    "L_values = [10, 20, 50]\n",
    "max_depth_values = [10, 15, 20]\n",
    "\n",
    "results = []\n",
    "\n",
    "for L in L_values:\n",
    "    for max_depth in max_depth_values:\n",
    "        print(f\"Training with L={L}, max_depth={max_depth}...\")\n",
    "\n",
    "        np.random.seed(777)\n",
    "        ensemble = rotation_forest(X_train_tuning, y_train_tuning, L=L, M=3, max_depth=max_depth)\n",
    "\n",
    "        # Evaluate on validation set\n",
    "        yHat_val = rotation_forest_predict(ensemble, X_val)\n",
    "        _, confusion_mat = confusion_matrix(y_val, yHat_val)\n",
    "        acc_val = accuracy(confusion_mat)\n",
    "\n",
    "        results.append({\n",
    "            'L': L,\n",
    "            'max_depth': max_depth,\n",
    "            'val_accuracy': acc_val\n",
    "        })\n",
    "        print(f\"  Validation accuracy: {acc_val:.4f}\")\n",
    "\n",
    "# Convert to DataFrame for easy viewing\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ],
   "id": "83962953f030e467"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Find best hyperparameters\n",
    "best_result = results_df.loc[results_df['val_accuracy'].idxmax()]\n",
    "print(\"Best hyperparameters:\")\n",
    "print(f\"  L = {int(best_result['L'])}\")\n",
    "print(f\"  max_depth = {int(best_result['max_depth'])}\")\n",
    "print(f\"  Validation accuracy = {best_result['val_accuracy']:.4f}\")"
   ],
   "id": "b0c21ba220425915"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Train final model with best hyperparameters on full training set\n",
    "best_L = int(best_result['L'])\n",
    "best_max_depth = int(best_result['max_depth'])\n",
    "\n",
    "print(f\"\\nTraining final model with L={best_L}, max_depth={best_max_depth}...\")\n",
    "np.random.seed(777)\n",
    "final_ensemble = rotation_forest(X_train, y_train, L=best_L, M=3, max_depth=best_max_depth)\n",
    "\n",
    "# Evaluate on test set\n",
    "yHat_final = rotation_forest_predict(final_ensemble, X_test)\n",
    "_, confusion_mat_final = confusion_matrix(y_test, yHat_final)\n",
    "accuracy_final = accuracy(confusion_mat_final)\n",
    "\n",
    "print(\"\\nFinal model performance on test set:\")\n",
    "print(f\"  L = {best_L}, max_depth = {best_max_depth}\")\n",
    "print(f\"  Test accuracy = {accuracy_final:.4f}\")\n",
    "print(f\"  Confusion matrix:\\n{confusion_mat_final}\")"
   ],
   "id": "7e79e211daf5ed4f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Visualization: Hyperparameter tuning results",
   "id": "9e96e7ed8c7449af"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Plot validation accuracy vs L for different max_depth values\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "for max_depth in max_depth_values:\n",
    "    subset = results_df[results_df['max_depth'] == max_depth]\n",
    "    ax.plot(subset['L'], subset['val_accuracy'], 'o-', label=f'max_depth={max_depth}', linewidth=2, markersize=8)\n",
    "\n",
    "ax.set_xlabel('Number of Trees (L)')\n",
    "ax.set_ylabel('Validation Accuracy')\n",
    "ax.set_title('Hyperparameter Tuning: Rotation Forest Performance')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "7161a03af4d6939d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Summary\n",
    "#\n",
    "# **Algorithm:** Rotation Forest ensemble classifier\n",
    "#\n",
    "# **Dataset:** Breast Cancer Wisconsin (Diagnostic) Dataset\n",
    "# - URL: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)\n",
    "# - 569 samples, 30 features, 2 classes (Benign vs Malignant)\n",
    "# - Larger dataset provides more reliable performance comparison\n",
    "#\n",
    "# **Implementation:**\n",
    "# - Disjoint feature subsets with M=3 features per subset\n",
    "# - 75% bootstrap sampling for PCA computation\n",
    "# - All PCA components retained per subset\n",
    "# - Standard PCA with mean-centering applied per subset\n",
    "# - Decision trees trained on rotated feature space\n",
    "#\n",
    "# **Results:**\n",
    "# - Rotation Forest demonstrates performance compared to Random Forest baseline\n",
    "# - Feature rotation via PCA increases diversity among trees\n",
    "# - Ensemble aggregation via majority voting improves individual tree predictions\n",
    "# - Larger dataset (569 vs 178 samples) provides more reliable evaluation\n"
   ],
   "id": "66f7aaa3da8748c8"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
