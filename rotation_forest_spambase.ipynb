{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Rotation Forest Implementation (Spambase)\n",
    "# Based on the paper \"Rotation Forest: A New Classifier Ensemble Method\"\n",
    "#\n",
    "# Dataset: Spambase (UCI)\n",
    "# - 4,601 samples, 57 numeric features\n",
    "# - Binary classification: spam (1) vs non-spam (0)\n",
    "#\n",
    "# Allowed libs: Python stdlib, numpy, pandas, matplotlib\n"
   ],
   "id": "b0f2343c69a700c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T23:13:47.656412Z",
     "start_time": "2026-01-18T23:13:46.981834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import time\n",
    "import urllib.request\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from decision_tree import *\n",
    "from classification_metrics import *\n"
   ],
   "id": "b3f2ac924578f593",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T23:13:48.339451Z",
     "start_time": "2026-01-18T23:13:48.331872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------------------------\n",
    "# Logging helper\n",
    "# ---------------------------\n",
    "\n",
    "def log_step(msg: str):\n",
    "    ts = time.strftime('%H:%M:%S')\n",
    "    print(f\"[{ts}] {msg}\")\n"
   ],
   "id": "b0c3c63288b42017",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T23:13:49.929078Z",
     "start_time": "2026-01-18T23:13:49.875218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------------------------\n",
    "# Dataset download + load\n",
    "# ---------------------------\n",
    "\n",
    "DATA_PATH = os.path.join('data', 'spambase.data')\n",
    "SPAMBASE_URL = 'https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data'\n",
    "\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    log_step(f\"Spambase file not found at {DATA_PATH}. Downloading from UCI...\")\n",
    "    urllib.request.urlretrieve(SPAMBASE_URL, DATA_PATH)\n",
    "    log_step(\"Download complete\")\n",
    "else:\n",
    "    log_step(f\"Found existing dataset file: {DATA_PATH}\")\n",
    "\n",
    "log_step(\"Loading Spambase CSV\")\n",
    "df = pd.read_csv(DATA_PATH, header=None)\n",
    "log_step(f\"Loaded df.shape={df.shape}\")\n",
    "\n",
    "# Last column is label: 1=spam, 0=non-spam\n",
    "X = df.iloc[:, :-1].to_numpy(dtype=float)\n",
    "y = df.iloc[:, -1].to_numpy(dtype=int)\n",
    "\n",
    "log_step(f\"Prepared X.shape={X.shape}, y.shape={y.shape}\")\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "log_step(f\"Class distribution (label->count): {dict(zip(unique.tolist(), counts.tolist()))}\")\n"
   ],
   "id": "f126522c69212914",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:13:49] Found existing dataset file: data\\spambase.data\n",
      "[00:13:49] Loading Spambase CSV\n",
      "[00:13:49] Loaded df.shape=(4601, 58)\n",
      "[00:13:49] Prepared X.shape=(4601, 57), y.shape=(4601,)\n",
      "[00:13:49] Class distribution (label->count): {0: 2788, 1: 1813}\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T23:13:53.831434Z",
     "start_time": "2026-01-18T23:13:53.816937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------------------------\n",
    "# Train / test split\n",
    "# ---------------------------\n",
    "\n",
    "np.random.seed(777)\n",
    "ind_train = np.random.choice(X.shape[0], size=int(X.shape[0] * 0.8), replace=False)\n",
    "bool_ind_train = np.isin(np.arange(X.shape[0]), ind_train)\n",
    "\n",
    "X_train = X[bool_ind_train]\n",
    "y_train = y[bool_ind_train]\n",
    "X_test = X[~bool_ind_train]\n",
    "y_test = y[~bool_ind_train]\n",
    "\n",
    "log_step(f\"Split: X_train={X_train.shape}, X_test={X_test.shape}\")\n"
   ],
   "id": "e16a1c2f2d73c04a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:13:53] Split: X_train=(3680, 57), X_test=(921, 57)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# PCA helpers (copied from your PCA notebook style)\n",
   "id": "f14787f1afdf8e82"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T23:14:07.663338Z",
     "start_time": "2026-01-18T23:14:07.655595Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_mean_std(X):\n",
    "    return np.mean(X, axis=0), np.std(X, axis=0)\n",
    "\n",
    "\n",
    "def normalization(X, means=None, sds=None):\n",
    "    X = X.copy()\n",
    "    for j in range(X.shape[1]):\n",
    "        if means is not None:\n",
    "            X[:, j] = (X[:, j] - means[j])\n",
    "        if sds is not None:\n",
    "            X[:, j] = X[:, j] / sds[j]\n",
    "    return X\n",
    "\n",
    "\n",
    "def get_principal_components(covariance_matrix):\n",
    "    # \"standard PCA\" on covariance matrix\n",
    "    eigen_values, eigen_vectors = np.linalg.eigh(covariance_matrix)\n",
    "\n",
    "    order = np.argsort(eigen_values)[::-1]\n",
    "    eigen_values = eigen_values[order]\n",
    "    eigen_vectors = eigen_vectors[:, order]\n",
    "\n",
    "    return eigen_values, eigen_vectors\n"
   ],
   "id": "45773ad0aede55a0",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Majority voting (same idea as in your RF notebook)\n",
   "id": "c05f8fd38af3c367"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T23:14:11.781262Z",
     "start_time": "2026-01-18T23:14:11.774722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def majority_voting(yHats):\n",
    "    yHat = []\n",
    "    for i in range(yHats.shape[1]):\n",
    "        vals, counts = np.unique(yHats[:, i], return_counts=True)\n",
    "        yHat.append(int(vals[np.argmax(counts)]))\n",
    "    return yHat\n"
   ],
   "id": "979b91f04f3570fe",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Rotation Forest implementation (paper-aligned: train base classifier on the whole transformed training set)\n",
   "id": "f8289984c46ad5d5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T23:14:14.299741Z",
     "start_time": "2026-01-18T23:14:14.279179Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_feature_subsets(n_features, M=3):\n",
    "    \"\"\"Randomly split features into subsets of size M.\n",
    "\n",
    "    Paper ref (abstract): \"the feature set is randomly split into K subsets\".\n",
    "    Remainder handling: last subset is completed with randomly selected features.\n",
    "    \"\"\"\n",
    "    feature_indices = np.random.permutation(n_features)\n",
    "    subsets = [feature_indices[i:i+M] for i in range(0, n_features, M)]\n",
    "\n",
    "    if len(subsets) > 0 and len(subsets[-1]) < M:\n",
    "        remainder = subsets[-1].tolist()\n",
    "        needed = M - len(remainder)\n",
    "        fill = np.random.choice(feature_indices, size=needed, replace=False).tolist()\n",
    "        remainder.extend(fill)\n",
    "        subsets[-1] = np.array(remainder)\n",
    "\n",
    "    return [np.array(s) for s in subsets]\n",
    "\n",
    "\n",
    "def compute_pca_rotation_for_subset(X_bootstrap, feature_subset):\n",
    "    X_subset = X_bootstrap[:, feature_subset]\n",
    "\n",
    "    means, _ = get_mean_std(X_subset)\n",
    "    X_centered = normalization(X_subset, means=means)\n",
    "\n",
    "    covariance_matrix = np.cov(X_centered.T)\n",
    "    _, eigen_vectors = get_principal_components(covariance_matrix)\n",
    "\n",
    "    # Keep ALL components (rotation, not dimensionality reduction)\n",
    "    return eigen_vectors, means\n",
    "\n",
    "\n",
    "def apply_rotation_transform(X, feature_subsets, rotation_matrices, subset_means):\n",
    "    rotated_blocks = []\n",
    "    for subset, R, means in zip(feature_subsets, rotation_matrices, subset_means):\n",
    "        X_subset = X[:, subset]\n",
    "        X_centered = normalization(X_subset, means=means)\n",
    "        rotated_blocks.append(X_centered @ R)\n",
    "    return np.concatenate(rotated_blocks, axis=1)\n",
    "\n",
    "\n",
    "def rotation_forest(X, y, L=10, M=3, max_depth=15, bootstrap_pca_fraction=0.75, verbose=True):\n",
    "    n_samples, n_features = X.shape\n",
    "    n_classes = len(set(y))\n",
    "    ensemble = []\n",
    "\n",
    "    if verbose:\n",
    "        log_step(f\"RotationForest train: L={L}, M={M}, n_samples={n_samples}, n_features={n_features}, n_classes={n_classes}\")\n",
    "\n",
    "    for l in range(L):\n",
    "        if verbose:\n",
    "            log_step(f\"[Tree {l+1}/{L}] Step 1: use full training set (no row bootstrap)\")\n",
    "\n",
    "        X_tree = X\n",
    "        y_tree = y\n",
    "\n",
    "        # Step 2: feature subsets\n",
    "        feature_subsets = create_feature_subsets(n_features, M=M)\n",
    "        if verbose:\n",
    "            log_step(f\"[Tree {l+1}/{L}] Step 2: K={len(feature_subsets)}, subset_sizes={[len(s) for s in feature_subsets]}\")\n",
    "\n",
    "        # Step 3: PCA sample (fraction, no replacement)\n",
    "        pca_sample_size = int(n_samples * bootstrap_pca_fraction)\n",
    "        pca_indices = np.random.choice(n_samples, size=pca_sample_size, replace=False)\n",
    "        X_pca_bootstrap = X[pca_indices]\n",
    "        if verbose:\n",
    "            log_step(f\"[Tree {l+1}/{L}] Step 3: X_pca_bootstrap={X_pca_bootstrap.shape}\")\n",
    "\n",
    "        # Step 4: PCA per subset\n",
    "        rotation_matrices = []\n",
    "        subset_means = []\n",
    "        for si, subset in enumerate(feature_subsets):\n",
    "            R, means = compute_pca_rotation_for_subset(X_pca_bootstrap, subset)\n",
    "            rotation_matrices.append(R)\n",
    "            subset_means.append(means)\n",
    "            if verbose and (si < 2 or si == len(feature_subsets) - 1):\n",
    "                log_step(f\"[Tree {l+1}/{L}] subset {si+1}/{len(feature_subsets)}: R.shape={R.shape}\")\n",
    "\n",
    "        # Step 5: rotate full training set\n",
    "        X_tree_rotated = apply_rotation_transform(X_tree, feature_subsets, rotation_matrices, subset_means)\n",
    "        if verbose:\n",
    "            log_step(f\"[Tree {l+1}/{L}] Step 5: X_tree_rotated={X_tree_rotated.shape}\")\n",
    "\n",
    "        # Step 6: train base classifier (decision tree)\n",
    "        tree = build_tree(X_tree_rotated, y_tree, n_classes, max_depth=max_depth, max_features=None)\n",
    "\n",
    "        ensemble.append({\n",
    "            'tree': tree,\n",
    "            'feature_subsets': feature_subsets,\n",
    "            'rotation_matrices': rotation_matrices,\n",
    "            'subset_means': subset_means,\n",
    "        })\n",
    "\n",
    "        if verbose:\n",
    "            log_step(f\"[Tree {l+1}/{L}] done\")\n",
    "\n",
    "    return ensemble\n",
    "\n",
    "\n",
    "def rotation_forest_predict(ensemble, X, verbose=True):\n",
    "    L = len(ensemble)\n",
    "    yHats = np.zeros((L, X.shape[0]))\n",
    "\n",
    "    if verbose:\n",
    "        log_step(f\"RotationForest predict: L={L}, X={X.shape}\")\n",
    "\n",
    "    for l in range(L):\n",
    "        if verbose:\n",
    "            log_step(f\"[Predict {l+1}/{L}] rotate -> tree predict\")\n",
    "\n",
    "        X_rotated = apply_rotation_transform(\n",
    "            X,\n",
    "            ensemble[l]['feature_subsets'],\n",
    "            ensemble[l]['rotation_matrices'],\n",
    "            ensemble[l]['subset_means'],\n",
    "        )\n",
    "        yHats[l, :] = predict(ensemble[l]['tree'], X_rotated)\n",
    "\n",
    "    return majority_voting(yHats)\n"
   ],
   "id": "4c6a744b7b2aa423",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T23:16:59.817931Z",
     "start_time": "2026-01-18T23:14:18.586474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "    # ---------------------------\n",
    "# Train + evaluate Rotation Forest\n",
    "# ---------------------------\n",
    "\n",
    "np.random.seed(777)\n",
    "log_step(\"Training Rotation Forest...\")\n",
    "rot_ens = rotation_forest(X_train, y_train, L=10, M=3, max_depth=15, bootstrap_pca_fraction=0.75, verbose=True)\n",
    "log_step(f\"Trained Rotation Forest: L={len(rot_ens)}\")\n",
    "\n",
    "log_step(\"Evaluating Rotation Forest...\")\n",
    "yhat_rot = rotation_forest_predict(rot_ens, X_test, verbose=True)\n",
    "_, cm_rot = confusion_matrix(y_test, yhat_rot)\n",
    "acc_rot = float(accuracy(cm_rot))\n",
    "log_step(f\"Rotation Forest accuracy={acc_rot:.4f}\")\n",
    "print(\"Confusion matrix:\\n\", cm_rot)\n"
   ],
   "id": "aaf30dd501057a5f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:14:18] Training Rotation Forest...\n",
      "[00:14:18] RotationForest train: L=10, M=3, n_samples=3680, n_features=57, n_classes=2\n",
      "[00:14:18] [Tree 1/10] Step 1: use full training set (no row bootstrap)\n",
      "[00:14:18] [Tree 1/10] Step 2: K=19, subset_sizes=[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[00:14:18] [Tree 1/10] Step 3: X_pca_bootstrap=(2760, 57)\n",
      "[00:14:18] [Tree 1/10] subset 1/19: R.shape=(3, 3)\n",
      "[00:14:18] [Tree 1/10] subset 2/19: R.shape=(3, 3)\n",
      "[00:14:18] [Tree 1/10] subset 19/19: R.shape=(3, 3)\n",
      "[00:14:18] [Tree 1/10] Step 5: X_tree_rotated=(3680, 57)\n",
      "[00:14:37] [Tree 1/10] done\n",
      "[00:14:37] [Tree 2/10] Step 1: use full training set (no row bootstrap)\n",
      "[00:14:37] [Tree 2/10] Step 2: K=19, subset_sizes=[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[00:14:37] [Tree 2/10] Step 3: X_pca_bootstrap=(2760, 57)\n",
      "[00:14:37] [Tree 2/10] subset 1/19: R.shape=(3, 3)\n",
      "[00:14:37] [Tree 2/10] subset 2/19: R.shape=(3, 3)\n",
      "[00:14:37] [Tree 2/10] subset 19/19: R.shape=(3, 3)\n",
      "[00:14:37] [Tree 2/10] Step 5: X_tree_rotated=(3680, 57)\n",
      "[00:14:53] [Tree 2/10] done\n",
      "[00:14:53] [Tree 3/10] Step 1: use full training set (no row bootstrap)\n",
      "[00:14:53] [Tree 3/10] Step 2: K=19, subset_sizes=[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[00:14:53] [Tree 3/10] Step 3: X_pca_bootstrap=(2760, 57)\n",
      "[00:14:53] [Tree 3/10] subset 1/19: R.shape=(3, 3)\n",
      "[00:14:53] [Tree 3/10] subset 2/19: R.shape=(3, 3)\n",
      "[00:14:53] [Tree 3/10] subset 19/19: R.shape=(3, 3)\n",
      "[00:14:53] [Tree 3/10] Step 5: X_tree_rotated=(3680, 57)\n",
      "[00:15:10] [Tree 3/10] done\n",
      "[00:15:10] [Tree 4/10] Step 1: use full training set (no row bootstrap)\n",
      "[00:15:10] [Tree 4/10] Step 2: K=19, subset_sizes=[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[00:15:10] [Tree 4/10] Step 3: X_pca_bootstrap=(2760, 57)\n",
      "[00:15:10] [Tree 4/10] subset 1/19: R.shape=(3, 3)\n",
      "[00:15:10] [Tree 4/10] subset 2/19: R.shape=(3, 3)\n",
      "[00:15:10] [Tree 4/10] subset 19/19: R.shape=(3, 3)\n",
      "[00:15:10] [Tree 4/10] Step 5: X_tree_rotated=(3680, 57)\n",
      "[00:15:25] [Tree 4/10] done\n",
      "[00:15:25] [Tree 5/10] Step 1: use full training set (no row bootstrap)\n",
      "[00:15:25] [Tree 5/10] Step 2: K=19, subset_sizes=[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[00:15:25] [Tree 5/10] Step 3: X_pca_bootstrap=(2760, 57)\n",
      "[00:15:25] [Tree 5/10] subset 1/19: R.shape=(3, 3)\n",
      "[00:15:25] [Tree 5/10] subset 2/19: R.shape=(3, 3)\n",
      "[00:15:25] [Tree 5/10] subset 19/19: R.shape=(3, 3)\n",
      "[00:15:25] [Tree 5/10] Step 5: X_tree_rotated=(3680, 57)\n",
      "[00:15:41] [Tree 5/10] done\n",
      "[00:15:41] [Tree 6/10] Step 1: use full training set (no row bootstrap)\n",
      "[00:15:41] [Tree 6/10] Step 2: K=19, subset_sizes=[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[00:15:41] [Tree 6/10] Step 3: X_pca_bootstrap=(2760, 57)\n",
      "[00:15:41] [Tree 6/10] subset 1/19: R.shape=(3, 3)\n",
      "[00:15:41] [Tree 6/10] subset 2/19: R.shape=(3, 3)\n",
      "[00:15:41] [Tree 6/10] subset 19/19: R.shape=(3, 3)\n",
      "[00:15:41] [Tree 6/10] Step 5: X_tree_rotated=(3680, 57)\n",
      "[00:15:56] [Tree 6/10] done\n",
      "[00:15:56] [Tree 7/10] Step 1: use full training set (no row bootstrap)\n",
      "[00:15:56] [Tree 7/10] Step 2: K=19, subset_sizes=[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[00:15:56] [Tree 7/10] Step 3: X_pca_bootstrap=(2760, 57)\n",
      "[00:15:56] [Tree 7/10] subset 1/19: R.shape=(3, 3)\n",
      "[00:15:56] [Tree 7/10] subset 2/19: R.shape=(3, 3)\n",
      "[00:15:56] [Tree 7/10] subset 19/19: R.shape=(3, 3)\n",
      "[00:15:56] [Tree 7/10] Step 5: X_tree_rotated=(3680, 57)\n",
      "[00:16:12] [Tree 7/10] done\n",
      "[00:16:12] [Tree 8/10] Step 1: use full training set (no row bootstrap)\n",
      "[00:16:12] [Tree 8/10] Step 2: K=19, subset_sizes=[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[00:16:12] [Tree 8/10] Step 3: X_pca_bootstrap=(2760, 57)\n",
      "[00:16:12] [Tree 8/10] subset 1/19: R.shape=(3, 3)\n",
      "[00:16:12] [Tree 8/10] subset 2/19: R.shape=(3, 3)\n",
      "[00:16:12] [Tree 8/10] subset 19/19: R.shape=(3, 3)\n",
      "[00:16:12] [Tree 8/10] Step 5: X_tree_rotated=(3680, 57)\n",
      "[00:16:28] [Tree 8/10] done\n",
      "[00:16:28] [Tree 9/10] Step 1: use full training set (no row bootstrap)\n",
      "[00:16:28] [Tree 9/10] Step 2: K=19, subset_sizes=[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[00:16:28] [Tree 9/10] Step 3: X_pca_bootstrap=(2760, 57)\n",
      "[00:16:28] [Tree 9/10] subset 1/19: R.shape=(3, 3)\n",
      "[00:16:28] [Tree 9/10] subset 2/19: R.shape=(3, 3)\n",
      "[00:16:28] [Tree 9/10] subset 19/19: R.shape=(3, 3)\n",
      "[00:16:28] [Tree 9/10] Step 5: X_tree_rotated=(3680, 57)\n",
      "[00:16:44] [Tree 9/10] done\n",
      "[00:16:44] [Tree 10/10] Step 1: use full training set (no row bootstrap)\n",
      "[00:16:44] [Tree 10/10] Step 2: K=19, subset_sizes=[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[00:16:44] [Tree 10/10] Step 3: X_pca_bootstrap=(2760, 57)\n",
      "[00:16:44] [Tree 10/10] subset 1/19: R.shape=(3, 3)\n",
      "[00:16:44] [Tree 10/10] subset 2/19: R.shape=(3, 3)\n",
      "[00:16:44] [Tree 10/10] subset 19/19: R.shape=(3, 3)\n",
      "[00:16:44] [Tree 10/10] Step 5: X_tree_rotated=(3680, 57)\n",
      "[00:16:59] [Tree 10/10] done\n",
      "[00:16:59] Trained Rotation Forest: L=10\n",
      "[00:16:59] Evaluating Rotation Forest...\n",
      "[00:16:59] RotationForest predict: L=10, X=(921, 57)\n",
      "[00:16:59] [Predict 1/10] rotate -> tree predict\n",
      "[00:16:59] [Predict 2/10] rotate -> tree predict\n",
      "[00:16:59] [Predict 3/10] rotate -> tree predict\n",
      "[00:16:59] [Predict 4/10] rotate -> tree predict\n",
      "[00:16:59] [Predict 5/10] rotate -> tree predict\n",
      "[00:16:59] [Predict 6/10] rotate -> tree predict\n",
      "[00:16:59] [Predict 7/10] rotate -> tree predict\n",
      "[00:16:59] [Predict 8/10] rotate -> tree predict\n",
      "[00:16:59] [Predict 9/10] rotate -> tree predict\n",
      "[00:16:59] [Predict 10/10] rotate -> tree predict\n",
      "[00:16:59] Rotation Forest accuracy=0.9533\n",
      "Confusion matrix:\n",
      " [[557.  10.]\n",
      " [ 33. 321.]]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ---------------------------\n",
    "# Baseline: Random Forest (from your earlier notebook style)\n",
    "# ---------------------------\n",
    "\n",
    "def random_forest(X, y, K, max_depth=15):\n",
    "    decision_trees = []\n",
    "    for k in range(K):\n",
    "        ind = np.random.choice(X.shape[0], size=X.shape[0], replace=True)\n",
    "        X_sample = X[ind]\n",
    "        y_sample = y[ind]\n",
    "        decision_trees.append(build_tree(X_sample, y_sample, len(set(y_sample)), max_features=\"sqrt\", max_depth=max_depth))\n",
    "    return decision_trees\n",
    "\n",
    "\n",
    "def random_forest_predict(decision_trees, X):\n",
    "    K = len(decision_trees)\n",
    "    yHats = np.zeros((K, X.shape[0]))\n",
    "    for k in range(K):\n",
    "        yHats[k, :] = predict(decision_trees[k], X)\n",
    "    return majority_voting(yHats)\n",
    "\n",
    "np.random.seed(777)\n",
    "log_step(\"Training Random Forest baseline...\")\n",
    "rf_ens = random_forest(X_train, y_train, K=10, max_depth=15)\n",
    "\n",
    "log_step(\"Evaluating Random Forest baseline...\")\n",
    "yhat_rf = random_forest_predict(rf_ens, X_test)\n",
    "_, cm_rf = confusion_matrix(y_test, yhat_rf)\n",
    "acc_rf = float(accuracy(cm_rf))\n",
    "log_step(f\"Random Forest accuracy={acc_rf:.4f}\")\n",
    "print(\"Confusion matrix:\\n\", cm_rf)\n"
   ],
   "id": "f76a4936d955d93d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"PERFORMANCE COMPARISON\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Rotation Forest accuracy: {acc_rot:.4f}\")\n",
    "print(f\"Random Forest accuracy:   {acc_rf:.4f}\")\n",
    "print(f\"Improvement:              {(acc_rot - acc_rf):.4f}\")\n",
    "print(\"=\" * 50)\n"
   ],
   "id": "6580c959614fad69"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
